{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Currency Overlay Simulation Engine\n",
    "\n",
    "## Professional Portfolio Risk Management and FX Hedging Optimization\n",
    "\n",
    "This notebook presents a comprehensive simulation engine for analyzing currency overlay strategies in multi-currency portfolios. We implement dynamic hedging strategies, volatility modeling, stress testing, and risk metrics to provide actionable insights for optimal hedge ratio selection.\n",
    "\n",
    "### Key Features:\n",
    "- **Synthetic FX Rate Generation**: 180-day simulation for USD, EUR, GBP, JPY, and EM Basket\n",
    "- **Multi-Currency Portfolio Modeling**: Realistic exposure weightings and performance tracking\n",
    "- **Dynamic Hedging Strategies**: 0%, 50%, and 100% hedge ratio analysis\n",
    "- **Advanced Volatility Modeling**: ARIMA and GARCH implementations\n",
    "- **Stress Testing**: Extreme FX movement scenarios\n",
    "- **Risk Metrics**: VaR and CVaR calculations\n",
    "- **Professional Visualizations**: Comprehensive charts and analysis\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series and volatility modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Risk calculations\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print(\"Plotting configuration set\")\n",
    "print(\"Random seed set for reproducibility\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Synthetic FX Rate Generation\n",
    "\n",
    "We'll generate realistic daily FX rates for 180 days using geometric Brownian motion with currency-specific parameters. Each currency pair will have different volatility and drift characteristics based on market observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation parameters\n",
    "SIMULATION_DAYS = 180\n",
    "START_DATE = pd.Timestamp('2024-01-01')\n",
    "\n",
    "# Currency parameters (based on typical market characteristics)\n",
    "currency_params = {\n",
    "    'USD': {'initial_rate': 1.0000, 'annual_vol': 0.00, 'drift': 0.0000},  # Base currency\n",
    "    'EUR': {'initial_rate': 1.0850, 'annual_vol': 0.12, 'drift': -0.0010},  # EUR/USD\n",
    "    'GBP': {'initial_rate': 1.2650, 'annual_vol': 0.14, 'drift': -0.0015},  # GBP/USD\n",
    "    'JPY': {'initial_rate': 0.0067, 'annual_vol': 0.11, 'drift': -0.0005},  # USD/JPY inverted\n",
    "    'EM_BASKET': {'initial_rate': 0.8500, 'annual_vol': 0.18, 'drift': -0.0020}  # EM/USD\n",
    "}\n",
    "\n",
    "def generate_fx_rates(currencies, params, days, start_date):\n",
    "    \"\"\"\n",
    "    Generate synthetic FX rates using geometric Brownian motion\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(start=start_date, periods=days, freq='D')\n",
    "    fx_data = pd.DataFrame(index=dates)\n",
    "    \n",
    "    dt = 1/252  # Daily time step (252 trading days per year)\n",
    "    \n",
    "    for currency in currencies:\n",
    "        if currency == 'USD':\n",
    "            # USD is base currency\n",
    "            fx_data[currency] = 1.0\n",
    "            continue\n",
    "            \n",
    "        # Extract parameters\n",
    "        S0 = params[currency]['initial_rate']\n",
    "        sigma = params[currency]['annual_vol']\n",
    "        mu = params[currency]['drift']\n",
    "        \n",
    "        # Generate random shocks\n",
    "        np.random.seed(42 + hash(currency) % 100)  # Different seed per currency\n",
    "        dW = np.random.normal(0, np.sqrt(dt), days)\n",
    "        \n",
    "        # Initialize rate series\n",
    "        rates = np.zeros(days)\n",
    "        rates[0] = S0\n",
    "        \n",
    "        # Generate rates using geometric Brownian motion\n",
    "        for t in range(1, days):\n",
    "            rates[t] = rates[t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * dW[t])\n",
    "        \n",
    "        fx_data[currency] = rates\n",
    "    \n",
    "    return fx_data\n",
    "\n",
    "# Generate FX rates\n",
    "currencies = ['USD', 'EUR', 'GBP', 'JPY', 'EM_BASKET']\n",
    "fx_rates = generate_fx_rates(currencies, currency_params, SIMULATION_DAYS, START_DATE)\n",
    "\n",
    "# Calculate daily returns\n",
    "fx_returns = fx_rates.pct_change().dropna()\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"FX Rate Generation Complete\")\n",
    "print(\"\\nInitial FX Rates:\")\n",
    "print(fx_rates.iloc[0])\n",
    "print(\"\\nFinal FX Rates:\")\n",
    "print(fx_rates.iloc[-1])\n",
    "print(\"\\nDaily Return Statistics:\")\n",
    "print(fx_returns.describe())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Multi-Currency Portfolio Setup\n",
    "\n",
    "We'll create a realistic portfolio with varying currency exposures. The portfolio will have underlying asset returns in local currencies plus FX translation effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio configuration\n",
    "INITIAL_PORTFOLIO_VALUE = 100_000_000  # $100M portfolio\n",
    "\n",
    "# Realistic currency exposure weights (based on typical global portfolio)\n",
    "portfolio_weights = {\n",
    "    'USD': 0.45,      # 45% US exposure\n",
    "    'EUR': 0.25,      # 25% European exposure  \n",
    "    'GBP': 0.10,      # 10% UK exposure\n",
    "    'JPY': 0.12,      # 12% Japanese exposure\n",
    "    'EM_BASKET': 0.08 # 8% Emerging markets exposure\n",
    "}\n",
    "\n",
    "# Verify weights sum to 1\n",
    "assert abs(sum(portfolio_weights.values()) - 1.0) < 1e-10\n",
    "\n",
    "def generate_local_asset_returns(currencies, days, start_date):\n",
    "    \"\"\"\n",
    "    Generate synthetic local currency asset returns (equity/bond returns before FX)\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(start=start_date, periods=days, freq='D')[1:]  # Exclude first day\n",
    "    local_returns = pd.DataFrame(index=dates)\n",
    "    \n",
    "    # Asset return parameters by region (annual figures)\n",
    "    asset_params = {\n",
    "        'USD': {'mean': 0.08, 'vol': 0.16},      # US equity-like returns\n",
    "        'EUR': {'mean': 0.06, 'vol': 0.18},      # European equity\n",
    "        'GBP': {'mean': 0.07, 'vol': 0.19},      # UK equity\n",
    "        'JPY': {'mean': 0.04, 'vol': 0.20},      # Japanese equity\n",
    "        'EM_BASKET': {'mean': 0.09, 'vol': 0.25} # EM equity (higher vol, higher return)\n",
    "    }\n",
    "    \n",
    "    dt = 1/252  # Daily time step\n",
    "    \n",
    "    for currency in currencies:\n",
    "        np.random.seed(123 + hash(currency) % 100)  # Different seed for asset returns\n",
    "        \n",
    "        mu = asset_params[currency]['mean']\n",
    "        sigma = asset_params[currency]['vol']\n",
    "        \n",
    "        # Generate daily returns (normal distribution)\n",
    "        daily_returns = np.random.normal(mu * dt, sigma * np.sqrt(dt), days - 1)\n",
    "        local_returns[f'{currency}_local'] = daily_returns\n",
    "    \n",
    "    return local_returns\n",
    "\n",
    "def calculate_unhedged_portfolio_returns(fx_returns, local_returns, weights):\n",
    "    \"\"\"\n",
    "    Calculate total portfolio returns including FX effects (unhedged)\n",
    "    Total return = Local asset return + FX return + Cross-effect\n",
    "    \"\"\"\n",
    "    portfolio_returns = pd.DataFrame(index=fx_returns.index)\n",
    "    \n",
    "    total_return = 0\n",
    "    for currency in weights.keys():\n",
    "        weight = weights[currency]\n",
    "        \n",
    "        if currency == 'USD':\n",
    "            # USD assets have no FX effect\n",
    "            currency_return = local_returns[f'{currency}_local'] * weight\n",
    "        else:\n",
    "            # Non-USD assets have FX translation effect\n",
    "            fx_return = fx_returns[currency]\n",
    "            local_return = local_returns[f'{currency}_local']\n",
    "            \n",
    "            # Total return = (1 + local) * (1 + fx) - 1 ≈ local + fx + local*fx\n",
    "            total_currency_return = local_return + fx_return + (local_return * fx_return)\n",
    "            currency_return = total_currency_return * weight\n",
    "        \n",
    "        portfolio_returns[f'{currency}_contribution'] = currency_return\n",
    "        total_return += currency_return\n",
    "    \n",
    "    portfolio_returns['total_return'] = total_return\n",
    "    return portfolio_returns\n",
    "\n",
    "# Generate local asset returns\n",
    "local_asset_returns = generate_local_asset_returns(currencies, SIMULATION_DAYS, START_DATE)\n",
    "\n",
    "# Calculate unhedged portfolio returns\n",
    "unhedged_returns = calculate_unhedged_portfolio_returns(fx_returns, local_asset_returns, portfolio_weights)\n",
    "\n",
    "# Calculate portfolio value evolution\n",
    "portfolio_values = pd.DataFrame(index=fx_rates.index)\n",
    "portfolio_values.iloc[0] = INITIAL_PORTFOLIO_VALUE\n",
    "\n",
    "for i in range(1, len(portfolio_values)):\n",
    "    portfolio_values.iloc[i] = portfolio_values.iloc[i-1] * (1 + unhedged_returns['total_return'].iloc[i-1])\n",
    "\n",
    "portfolio_values.columns = ['unhedged_value']\n",
    "\n",
    "print(\"Portfolio Setup Complete\")\n",
    "print(f\"\\nPortfolio Weights:\")\n",
    "for currency, weight in portfolio_weights.items():\n",
    "    print(f\"  {currency}: {weight:.1%}\")\n",
    "\n",
    "print(f\"\\nInitial Portfolio Value: ${INITIAL_PORTFOLIO_VALUE:,.0f}\")\n",
    "print(f\"Final Unhedged Value: ${portfolio_values.iloc[-1].values[0]:,.0f}\")\n",
    "print(f\"Total Unhedged Return: {(portfolio_values.iloc[-1].values[0]/INITIAL_PORTFOLIO_VALUE - 1):.2%}\")\n",
    "\n",
    "print(f\"\\nDaily Return Statistics (Unhedged):\")\n",
    "print(unhedged_returns['total_return'].describe())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Dynamic Hedge Ratio Implementation\n",
    "\n",
    "We'll implement three hedge ratio strategies:\n",
    "- **0% Hedge**: No FX hedging (full currency exposure)\n",
    "- **50% Hedge**: Partial hedging (moderate currency exposure)  \n",
    "- **100% Hedge**: Full FX hedging (minimal currency exposure)\n",
    "\n",
    "Hedging is simulated through forward contracts that eliminate FX risk proportionally to the hedge ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hedged_portfolio_returns(fx_returns, local_returns, weights, hedge_ratio):\n",
    "    \"\"\"\n",
    "    Calculate portfolio returns with specified hedge ratio\n",
    "    \n",
    "    hedge_ratio: 0.0 = no hedging, 1.0 = full hedging\n",
    "    Hedging reduces FX impact proportionally to hedge ratio\n",
    "    \"\"\"\n",
    "    portfolio_returns = pd.DataFrame(index=fx_returns.index)\n",
    "    \n",
    "    total_return = 0\n",
    "    for currency in weights.keys():\n",
    "        weight = weights[currency]\n",
    "        \n",
    "        if currency == 'USD':\n",
    "            # USD assets have no FX effect regardless of hedging\n",
    "            currency_return = local_returns[f'{currency}_local'] * weight\n",
    "        else:\n",
    "            # Non-USD assets: apply hedge ratio to FX component\n",
    "            fx_return = fx_returns[currency]\n",
    "            local_return = local_returns[f'{currency}_local']\n",
    "            \n",
    "            # Hedged FX return = (1 - hedge_ratio) * fx_return\n",
    "            hedged_fx_return = (1 - hedge_ratio) * fx_return\n",
    "            \n",
    "            # Total return with hedging\n",
    "            total_currency_return = local_return + hedged_fx_return + (local_return * hedged_fx_return)\n",
    "            currency_return = total_currency_return * weight\n",
    "        \n",
    "        portfolio_returns[f'{currency}_contribution'] = currency_return\n",
    "        total_return += currency_return\n",
    "    \n",
    "    portfolio_returns['total_return'] = total_return\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_hedging_cost(hedge_ratio, notional_exposure):\n",
    "    \"\"\"\n",
    "    Simplified hedging cost calculation\n",
    "    Assumes 0.1% annual cost for full hedging, scaled by hedge ratio and exposure\n",
    "    \"\"\"\n",
    "    annual_cost_rate = 0.001  # 0.1% annual\n",
    "    daily_cost_rate = annual_cost_rate / 252\n",
    "    \n",
    "    # Cost proportional to hedge ratio and non-USD exposure\n",
    "    non_usd_weight = 1 - portfolio_weights['USD']  # 55% non-USD exposure\n",
    "    daily_cost = hedge_ratio * non_usd_weight * daily_cost_rate\n",
    "    \n",
    "    return daily_cost\n",
    "\n",
    "# Define hedge ratios to analyze\n",
    "hedge_ratios = [0.0, 0.5, 1.0]\n",
    "hedge_labels = ['Unhedged (0%)', 'Partial Hedge (50%)', 'Full Hedge (100%)']\n",
    "\n",
    "# Calculate returns for each hedge ratio\n",
    "hedged_results = {}\n",
    "portfolio_values_all = pd.DataFrame(index=fx_rates.index)\n",
    "portfolio_values_all['unhedged_value'] = portfolio_values['unhedged_value']\n",
    "\n",
    "for i, hedge_ratio in enumerate(hedge_ratios):\n",
    "    label = hedge_labels[i]\n",
    "    \n",
    "    if hedge_ratio == 0.0:\n",
    "        # Use existing unhedged results\n",
    "        hedged_results[label] = unhedged_returns.copy()\n",
    "    else:\n",
    "        # Calculate hedged returns\n",
    "        hedged_returns = calculate_hedged_portfolio_returns(\n",
    "            fx_returns, local_asset_returns, portfolio_weights, hedge_ratio\n",
    "        )\n",
    "        \n",
    "        # Subtract hedging costs\n",
    "        hedging_cost = calculate_hedging_cost(hedge_ratio, INITIAL_PORTFOLIO_VALUE)\n",
    "        hedged_returns['total_return'] -= hedging_cost\n",
    "        \n",
    "        hedged_results[label] = hedged_returns\n",
    "    \n",
    "    # Calculate portfolio value evolution for this hedge ratio\n",
    "    values = pd.Series(index=fx_rates.index, dtype=float)\n",
    "    values.iloc[0] = INITIAL_PORTFOLIO_VALUE\n",
    "    \n",
    "    for j in range(1, len(values)):\n",
    "        values.iloc[j] = values.iloc[j-1] * (1 + hedged_results[label]['total_return'].iloc[j-1])\n",
    "    \n",
    "    portfolio_values_all[f'{label.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"%\", \"pct\")}_value'] = values\n",
    "\n",
    "# Performance summary\n",
    "print(\"Hedge Ratio Analysis Complete\")\n",
    "print(\"\\nPerformance Summary (180-day period):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, hedge_ratio in enumerate(hedge_ratios):\n",
    "    label = hedge_labels[i]\n",
    "    col_name = f'{label.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"%\", \"pct\")}_value'\n",
    "    \n",
    "    initial_val = portfolio_values_all[col_name].iloc[0]\n",
    "    final_val = portfolio_values_all[col_name].iloc[-1]\n",
    "    total_return = (final_val / initial_val - 1)\n",
    "    \n",
    "    returns_series = hedged_results[label]['total_return']\n",
    "    volatility = returns_series.std() * np.sqrt(252)  # Annualized\n",
    "    sharpe = (returns_series.mean() * 252) / volatility if volatility > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  Final Value: ${final_val:,.0f}\")\n",
    "    print(f\"  Total Return: {total_return:.2%}\")\n",
    "    print(f\"  Annualized Vol: {volatility:.2%}\")\n",
    "    print(f\"  Sharpe Ratio: {sharpe:.3f}\")\n",
    "\n",
    "# Calculate correlation matrix of hedge strategies\n",
    "hedge_returns_df = pd.DataFrame()\n",
    "for i, hedge_ratio in enumerate(hedge_ratios):\n",
    "    label = hedge_labels[i]\n",
    "    hedge_returns_df[label] = hedged_results[label]['total_return']\n",
    "\n",
    "print(f\"\\nCorrelation Matrix:\")\n",
    "print(hedge_returns_df.corr().round(3))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Advanced Volatility Modeling with ARIMA and GARCH\n",
    "\n",
    "We'll implement time series models to forecast volatility:\n",
    "- **ARIMA**: For modeling the mean-reverting component of returns\n",
    "- **GARCH**: For modeling time-varying volatility clustering\n",
    "- **Forecasting**: Project future risk profiles for risk management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_arima_garch_model(returns_series, currency_name):\n",
    "    \"\"\"\n",
    "    Fit ARIMA-GARCH model to currency returns\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove any infinite or NaN values\n",
    "        returns_clean = returns_series.dropna()\n",
    "        returns_clean = returns_clean[np.isfinite(returns_clean)]\n",
    "        \n",
    "        if len(returns_clean) < 50:  # Need minimum data\n",
    "            return None, None, None\n",
    "        \n",
    "        # Convert to percentage for numerical stability\n",
    "        returns_pct = returns_clean * 100\n",
    "        \n",
    "        # Step 1: Fit ARIMA model for mean equation\n",
    "        # Use simple ARIMA(1,0,1) for mean\n",
    "        try:\n",
    "            arima_model = ARIMA(returns_pct, order=(1, 0, 1))\n",
    "            arima_fit = arima_model.fit()\n",
    "            arima_residuals = arima_fit.resid\n",
    "        except:\n",
    "            # Fallback to simpler model if convergence issues\n",
    "            arima_model = ARIMA(returns_pct, order=(0, 0, 0))\n",
    "            arima_fit = arima_model.fit()\n",
    "            arima_residuals = arima_fit.resid\n",
    "        \n",
    "        # Step 2: Fit GARCH model for volatility\n",
    "        # Use GARCH(1,1) which is standard in finance\n",
    "        try:\n",
    "            garch_model = arch_model(arima_residuals, vol='GARCH', p=1, q=1, rescale=False)\n",
    "            garch_fit = garch_model.fit(disp='off')\n",
    "            \n",
    "            # Generate volatility forecasts\n",
    "            forecast_horizon = 30  # 30-day forecast\n",
    "            forecasts = garch_fit.forecast(horizon=forecast_horizon)\n",
    "            vol_forecast = np.sqrt(forecasts.variance.values[-1, :])  # Convert to volatility\n",
    "            \n",
    "        except:\n",
    "            # Fallback: use rolling volatility if GARCH fails\n",
    "            vol_forecast = np.full(30, returns_clean.std() * 100)\n",
    "            garch_fit = None\n",
    "        \n",
    "        return arima_fit, garch_fit, vol_forecast / 100  # Convert back from percentage\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Model fitting failed for {currency_name}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def analyze_volatility_patterns(fx_returns):\n",
    "    \"\"\"\n",
    "    Analyze volatility patterns and clustering\n",
    "    \"\"\"\n",
    "    vol_analysis = {}\n",
    "    \n",
    "    for currency in fx_returns.columns:\n",
    "        if currency == 'USD':\n",
    "            continue  # Skip USD (base currency)\n",
    "            \n",
    "        returns = fx_returns[currency]\n",
    "        \n",
    "        # Calculate rolling volatility (21-day window)\n",
    "        rolling_vol = returns.rolling(window=21).std() * np.sqrt(252)  # Annualized\n",
    "        \n",
    "        # Volatility clustering test (Ljung-Box on squared returns)\n",
    "        try:\n",
    "            lb_test = acorr_ljungbox(returns**2, lags=10, return_df=True)\n",
    "            volatility_clustering = lb_test['lb_pvalue'].iloc[4] < 0.05  # 5-day lag\n",
    "        except:\n",
    "            volatility_clustering = False\n",
    "        \n",
    "        # Fit ARIMA-GARCH\n",
    "        arima_fit, garch_fit, vol_forecast = fit_arima_garch_model(returns, currency)\n",
    "        \n",
    "        vol_analysis[currency] = {\n",
    "            'rolling_vol': rolling_vol,\n",
    "            'vol_clustering': volatility_clustering,\n",
    "            'arima_model': arima_fit,\n",
    "            'garch_model': garch_fit,\n",
    "            'vol_forecast': vol_forecast,\n",
    "            'current_vol': rolling_vol.iloc[-1] if not pd.isna(rolling_vol.iloc[-1]) else returns.std() * np.sqrt(252)\n",
    "        }\n",
    "    \n",
    "    return vol_analysis\n",
    "\n",
    "# Perform volatility analysis\n",
    "print(\"Performing Volatility Analysis...\")\n",
    "volatility_analysis = analyze_volatility_patterns(fx_returns)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nVolatility Modeling Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "forecast_summary = pd.DataFrame()\n",
    "\n",
    "for currency, analysis in volatility_analysis.items():\n",
    "    current_vol = analysis['current_vol']\n",
    "    vol_clustering = analysis['vol_clustering']\n",
    "    \n",
    "    print(f\"\\n{currency}:\")\n",
    "    print(f\"  Current Volatility: {current_vol:.2%}\")\n",
    "    print(f\"  Volatility Clustering: {'Yes' if vol_clustering else 'No'}\")\n",
    "    \n",
    "    if analysis['vol_forecast'] is not None:\n",
    "        avg_forecast_vol = np.mean(analysis['vol_forecast']) * np.sqrt(252)\n",
    "        print(f\"  30-day Vol Forecast: {avg_forecast_vol:.2%}\")\n",
    "        \n",
    "        # Store for summary\n",
    "        forecast_summary.loc[currency, 'Current_Vol'] = current_vol\n",
    "        forecast_summary.loc[currency, 'Forecast_Vol'] = avg_forecast_vol\n",
    "        forecast_summary.loc[currency, 'Vol_Change'] = avg_forecast_vol - current_vol\n",
    "    else:\n",
    "        print(f\"  Model Fitting: Failed\")\n",
    "\n",
    "# Display forecast summary\n",
    "if not forecast_summary.empty:\n",
    "    print(f\"\\nVolatility Forecast Summary:\")\n",
    "    print(forecast_summary.round(4))\n",
    "\n",
    "# Calculate portfolio-level volatility forecast\n",
    "print(f\"\\nPortfolio-Level Volatility Analysis:\")\n",
    "\n",
    "# Current portfolio volatility (from recent returns)\n",
    "recent_returns = hedge_returns_df['Unhedged (0%)'].tail(30)  # Last 30 days\n",
    "current_portfolio_vol = recent_returns.std() * np.sqrt(252)\n",
    "\n",
    "print(f\"Current Portfolio Volatility: {current_portfolio_vol:.2%}\")\n",
    "\n",
    "# Forecasted portfolio volatility (weighted by currency exposures)\n",
    "if not forecast_summary.empty:\n",
    "    # Exclude USD from non-USD currencies\n",
    "    non_usd_currencies = [c for c in forecast_summary.index if c != 'USD']\n",
    "    \n",
    "    # Weight forecast volatilities by portfolio weights\n",
    "    forecast_portfolio_vol = 0\n",
    "    for currency in non_usd_currencies:\n",
    "        if currency in portfolio_weights and currency in forecast_summary.index:\n",
    "            weight = portfolio_weights[currency]\n",
    "            forecast_vol = forecast_summary.loc[currency, 'Forecast_Vol']\n",
    "            forecast_portfolio_vol += (weight * forecast_vol) ** 2\n",
    "    \n",
    "    forecast_portfolio_vol = np.sqrt(forecast_portfolio_vol)\n",
    "    \n",
    "    print(f\"Forecasted Portfolio Volatility: {forecast_portfolio_vol:.2%}\")\n",
    "    print(f\"Expected Volatility Change: {forecast_portfolio_vol - current_portfolio_vol:+.2%}\")\n",
    "\n",
    "print(\"Volatility Modeling Complete\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Stress Testing and Scenario Analysis\n",
    "\n",
    "We'll simulate extreme FX scenarios to test portfolio resilience:\n",
    "- **Currency Appreciation**: Sudden 15% strengthening against USD\n",
    "- **Currency Depreciation**: Sudden 15% weakening against USD  \n",
    "- **Correlated Stress**: Multiple currencies moving together\n",
    "- **Impact Assessment**: Portfolio effects under different hedge ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stress_scenarios():\n",
    "    \"\"\"\n",
    "    Create various FX stress scenarios\n",
    "    \"\"\"\n",
    "    scenarios = {}\n",
    "    \n",
    "    # Individual currency stress (15% moves)\n",
    "    for currency in ['EUR', 'GBP', 'JPY', 'EM_BASKET']:\n",
    "        # Appreciation scenario\n",
    "        scenarios[f'{currency}_appreciation'] = {\n",
    "            'name': f'{currency} +15% Appreciation',\n",
    "            'shocks': {currency: 0.15},\n",
    "            'description': f'Sudden 15% strengthening of {currency} against USD'\n",
    "        }\n",
    "        \n",
    "        # Depreciation scenario  \n",
    "        scenarios[f'{currency}_depreciation'] = {\n",
    "            'name': f'{currency} -15% Depreciation',\n",
    "            'shocks': {currency: -0.15},\n",
    "            'description': f'Sudden 15% weakening of {currency} against USD'\n",
    "        }\n",
    "    \n",
    "    # Correlated stress scenarios\n",
    "    scenarios['developed_appreciation'] = {\n",
    "        'name': 'Developed Markets +10% Appreciation',\n",
    "        'shocks': {'EUR': 0.10, 'GBP': 0.10, 'JPY': 0.10},\n",
    "        'description': 'Simultaneous strengthening of developed market currencies'\n",
    "    }\n",
    "    \n",
    "    scenarios['developed_depreciation'] = {\n",
    "        'name': 'Developed Markets -10% Depreciation', \n",
    "        'shocks': {'EUR': -0.10, 'GBP': -0.10, 'JPY': -0.10},\n",
    "        'description': 'Simultaneous weakening of developed market currencies'\n",
    "    }\n",
    "    \n",
    "    scenarios['em_crisis'] = {\n",
    "        'name': 'EM Crisis -25% Depreciation',\n",
    "        'shocks': {'EM_BASKET': -0.25},\n",
    "        'description': 'Severe emerging markets currency crisis'\n",
    "    }\n",
    "    \n",
    "    scenarios['usd_weakness'] = {\n",
    "        'name': 'Broad USD Weakness',\n",
    "        'shocks': {'EUR': 0.12, 'GBP': 0.15, 'JPY': 0.08, 'EM_BASKET': 0.20},\n",
    "        'description': 'Broad-based USD weakening across all currencies'\n",
    "    }\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "def calculate_stress_impact(scenario_shocks, portfolio_weights, hedge_ratio):\n",
    "    \"\"\"\n",
    "    Calculate portfolio impact from FX stress scenario\n",
    "    \"\"\"\n",
    "    total_impact = 0\n",
    "    \n",
    "    for currency, weight in portfolio_weights.items():\n",
    "        if currency == 'USD':\n",
    "            continue  # No FX impact for USD assets\n",
    "            \n",
    "        # Get FX shock for this currency\n",
    "        fx_shock = scenario_shocks.get(currency, 0.0)\n",
    "        \n",
    "        # Apply hedge ratio (hedging reduces FX impact)\n",
    "        hedged_fx_shock = fx_shock * (1 - hedge_ratio)\n",
    "        \n",
    "        # Portfolio impact = weight × FX shock\n",
    "        # (Assuming no correlation with local asset returns for stress test)\n",
    "        currency_impact = weight * hedged_fx_shock\n",
    "        total_impact += currency_impact\n",
    "    \n",
    "    return total_impact\n",
    "\n",
    "def run_stress_tests(scenarios, portfolio_weights, hedge_ratios, hedge_labels, initial_value):\n",
    "    \"\"\"\n",
    "    Run comprehensive stress testing\n",
    "    \"\"\"\n",
    "    stress_results = pd.DataFrame()\n",
    "    \n",
    "    for scenario_key, scenario_data in scenarios.items():\n",
    "        scenario_name = scenario_data['name']\n",
    "        shocks = scenario_data['shocks']\n",
    "        \n",
    "        row_data = {'Scenario': scenario_name}\n",
    "        \n",
    "        for i, hedge_ratio in enumerate(hedge_ratios):\n",
    "            hedge_label = hedge_labels[i]\n",
    "            \n",
    "            # Calculate portfolio impact\n",
    "            impact = calculate_stress_impact(shocks, portfolio_weights, hedge_ratio)\n",
    "            \n",
    "            # Convert to dollar impact\n",
    "            dollar_impact = initial_value * impact\n",
    "            \n",
    "            row_data[f'{hedge_label}_Impact_%'] = impact * 100  # Percentage\n",
    "            row_data[f'{hedge_label}_Impact_$'] = dollar_impact\n",
    "        \n",
    "        stress_results = pd.concat([stress_results, pd.DataFrame([row_data])], ignore_index=True)\n",
    "    \n",
    "    return stress_results\n",
    "\n",
    "# Run stress testing\n",
    "print(\"Running Stress Testing...\")\n",
    "\n",
    "stress_scenarios = create_stress_scenarios()\n",
    "stress_results = run_stress_tests(\n",
    "    stress_scenarios, \n",
    "    portfolio_weights, \n",
    "    hedge_ratios, \n",
    "    hedge_labels, \n",
    "    INITIAL_PORTFOLIO_VALUE\n",
    ")\n",
    "\n",
    "# Display stress test results\n",
    "print(\"\\nStress Test Results:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create summary table for easy viewing\n",
    "display_cols = ['Scenario', 'Unhedged (0%)_Impact_%', 'Partial Hedge (50%)_Impact_%', 'Full Hedge (100%)_Impact_%']\n",
    "stress_summary = stress_results[display_cols].copy()\n",
    "stress_summary.columns = ['Scenario', 'Unhedged (%)', 'Partial Hedge (%)', 'Full Hedge (%)']\n",
    "\n",
    "print(stress_summary.round(2))\n",
    "\n",
    "# Identify worst-case scenarios for each hedge strategy\n",
    "print(f\"\\nWorst-Case Scenario Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for hedge_label in hedge_labels:\n",
    "    impact_col = f'{hedge_label}_Impact_%'\n",
    "    worst_scenario_idx = stress_results[impact_col].abs().idxmax()\n",
    "    worst_scenario = stress_results.loc[worst_scenario_idx]\n",
    "    \n",
    "    print(f\"\\n{hedge_label}:\")\n",
    "    print(f\"  Worst Scenario: {worst_scenario['Scenario']}\")\n",
    "    print(f\"  Impact: {worst_scenario[impact_col]:.2f}%\")\n",
    "    print(f\"  Dollar Loss: ${abs(worst_scenario[f'{hedge_label}_Impact_$']):,.0f}\")\n",
    "\n",
    "# Calculate hedge effectiveness\n",
    "print(f\"\\nHedge Effectiveness Analysis:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "hedge_effectiveness = pd.DataFrame()\n",
    "\n",
    "for _, row in stress_results.iterrows():\n",
    "    scenario = row['Scenario']\n",
    "    unhedged_impact = abs(row['Unhedged (0%)_Impact_%'])\n",
    "    partial_impact = abs(row['Partial Hedge (50%)_Impact_%'])\n",
    "    full_impact = abs(row['Full Hedge (100%)_Impact_%'])\n",
    "    \n",
    "    # Calculate risk reduction\n",
    "    partial_reduction = (unhedged_impact - partial_impact) / unhedged_impact * 100 if unhedged_impact != 0 else 0\n",
    "    full_reduction = (unhedged_impact - full_impact) / unhedged_impact * 100 if unhedged_impact != 0 else 0\n",
    "    \n",
    "    hedge_effectiveness = pd.concat([\n",
    "        hedge_effectiveness, \n",
    "        pd.DataFrame([{\n",
    "            'Scenario': scenario,\n",
    "            'Unhedged_Risk': unhedged_impact,\n",
    "            '50%_Hedge_Reduction': partial_reduction,\n",
    "            '100%_Hedge_Reduction': full_reduction\n",
    "        }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "print(hedge_effectiveness.round(2))\n",
    "\n",
    "# Calculate average hedge effectiveness\n",
    "avg_partial_effectiveness = hedge_effectiveness['50%_Hedge_Reduction'].mean()\n",
    "avg_full_effectiveness = hedge_effectiveness['100%_Hedge_Reduction'].mean()\n",
    "\n",
    "print(f\"\\nAverage Hedge Effectiveness:\")\n",
    "print(f\"  50% Hedge Strategy: {avg_partial_effectiveness:.1f}% risk reduction\")\n",
    "print(f\"  100% Hedge Strategy: {avg_full_effectiveness:.1f}% risk reduction\")\n",
    "\n",
    "print(\"\\nStress Testing Complete\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Risk Metrics: VaR and CVaR Analysis\n",
    "\n",
    "We'll calculate comprehensive risk metrics for portfolio optimization:\n",
    "- **Value at Risk (VaR)**: Maximum expected loss at given confidence levels\n",
    "- **Conditional VaR (CVaR)**: Expected loss beyond the VaR threshold\n",
    "- **Multiple Methods**: Historical, Parametric, and Monte Carlo approaches\n",
    "- **Hedge Comparison**: Risk metrics across different hedge ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_var_cvar(returns, confidence_levels=[0.95, 0.99], portfolio_value=1):\n",
    "    \"\"\"\n",
    "    Calculate VaR and CVaR using multiple methods\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Remove any NaN values\n",
    "    returns_clean = returns.dropna()\n",
    "    \n",
    "    for confidence_level in confidence_levels:\n",
    "        alpha = 1 - confidence_level\n",
    "        \n",
    "        # Method 1: Historical VaR/CVaR\n",
    "        historical_var = np.percentile(returns_clean, alpha * 100)\n",
    "        tail_returns = returns_clean[returns_clean <= historical_var]\n",
    "        historical_cvar = tail_returns.mean() if len(tail_returns) > 0 else historical_var\n",
    "        \n",
    "        # Method 2: Parametric VaR/CVaR (assuming normal distribution)\n",
    "        mu = returns_clean.mean()\n",
    "        sigma = returns_clean.std()\n",
    "        parametric_var = norm.ppf(alpha, mu, sigma)\n",
    "        \n",
    "        # CVaR for normal distribution\n",
    "        parametric_cvar = mu - sigma * norm.pdf(norm.ppf(alpha)) / alpha\n",
    "        \n",
    "        # Method 3: Monte Carlo VaR/CVaR\n",
    "        np.random.seed(42)\n",
    "        n_simulations = 10000\n",
    "        simulated_returns = np.random.normal(mu, sigma, n_simulations)\n",
    "        mc_var = np.percentile(simulated_returns, alpha * 100)\n",
    "        mc_tail = simulated_returns[simulated_returns <= mc_var]\n",
    "        mc_cvar = mc_tail.mean() if len(mc_tail) > 0 else mc_var\n",
    "        \n",
    "        # Convert to dollar amounts\n",
    "        results[f'{confidence_level:.0%}'] = {\n",
    "            'Historical_VaR': historical_var * portfolio_value,\n",
    "            'Historical_CVaR': historical_cvar * portfolio_value,\n",
    "            'Parametric_VaR': parametric_var * portfolio_value,\n",
    "            'Parametric_CVaR': parametric_cvar * portfolio_value,\n",
    "            'MonteCarlo_VaR': mc_var * portfolio_value,\n",
    "            'MonteCarlo_CVaR': mc_cvar * portfolio_value,\n",
    "            'Historical_VaR_%': historical_var * 100,\n",
    "            'Historical_CVaR_%': historical_cvar * 100,\n",
    "            'Parametric_VaR_%': parametric_var * 100,\n",
    "            'Parametric_CVaR_%': parametric_cvar * 100\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_risk_adjusted_metrics(returns, portfolio_value=1):\n",
    "    \"\"\"\n",
    "    Calculate additional risk-adjusted performance metrics\n",
    "    \"\"\"\n",
    "    returns_clean = returns.dropna()\n",
    "    \n",
    "    # Annualized metrics\n",
    "    annual_return = returns_clean.mean() * 252\n",
    "    annual_volatility = returns_clean.std() * np.sqrt(252)\n",
    "    sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "    \n",
    "    # Downside metrics\n",
    "    downside_returns = returns_clean[returns_clean < 0]\n",
    "    downside_deviation = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0\n",
    "    sortino_ratio = annual_return / downside_deviation if downside_deviation > 0 else 0\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative_returns = (1 + returns_clean).cumprod()\n",
    "    rolling_max = cumulative_returns.expanding().max()\n",
    "    drawdowns = (cumulative_returns - rolling_max) / rolling_max\n",
    "    max_drawdown = drawdowns.min()\n",
    "    \n",
    "    # Hit ratio (percentage of positive days)\n",
    "    hit_ratio = (returns_clean > 0).mean()\n",
    "    \n",
    "    return {\n",
    "        'Annual_Return_%': annual_return * 100,\n",
    "        'Annual_Volatility_%': annual_volatility * 100,\n",
    "        'Sharpe_Ratio': sharpe_ratio,\n",
    "        'Sortino_Ratio': sortino_ratio,\n",
    "        'Max_Drawdown_%': max_drawdown * 100,\n",
    "        'Hit_Ratio_%': hit_ratio * 100,\n",
    "        'Downside_Deviation_%': downside_deviation * 100\n",
    "    }\n",
    "\n",
    "# Calculate VaR and CVaR for each hedge strategy\n",
    "print(\"Calculating Risk Metrics...\")\n",
    "\n",
    "confidence_levels = [0.95, 0.99]\n",
    "risk_metrics_summary = pd.DataFrame()\n",
    "\n",
    "for i, hedge_ratio in enumerate(hedge_ratios):\n",
    "    hedge_label = hedge_labels[i]\n",
    "    returns = hedged_results[hedge_label]['total_return']\n",
    "    \n",
    "    print(f\"\\nAnalyzing {hedge_label}...\")\n",
    "    \n",
    "    # Calculate VaR/CVaR\n",
    "    var_cvar_results = calculate_var_cvar(returns, confidence_levels, INITIAL_PORTFOLIO_VALUE)\n",
    "    \n",
    "    # Calculate risk-adjusted metrics\n",
    "    risk_adjusted = calculate_risk_adjusted_metrics(returns, INITIAL_PORTFOLIO_VALUE)\n",
    "    \n",
    "    # Combine results\n",
    "    row_data = {'Strategy': hedge_label}\n",
    "    row_data.update(risk_adjusted)\n",
    "    \n",
    "    # Add VaR/CVaR results\n",
    "    for conf_level, metrics in var_cvar_results.items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            if metric_name.endswith('_%'):\n",
    "                row_data[f'{conf_level}_{metric_name}'] = value\n",
    "            elif metric_name.endswith('_VaR') or metric_name.endswith('_CVaR'):\n",
    "                row_data[f'{conf_level}_{metric_name}'] = value\n",
    "    \n",
    "    risk_metrics_summary = pd.concat([risk_metrics_summary, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# Display comprehensive risk metrics\n",
    "print(\"\\nComprehensive Risk Metrics Summary:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Performance metrics\n",
    "performance_cols = ['Strategy', 'Annual_Return_%', 'Annual_Volatility_%', 'Sharpe_Ratio', 'Sortino_Ratio', 'Max_Drawdown_%']\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(risk_metrics_summary[performance_cols].round(3))\n",
    "\n",
    "# VaR metrics (95% confidence)\n",
    "var_95_cols = ['Strategy', '95%_Historical_VaR_%', '95%_Parametric_VaR_%', '95%_Historical_CVaR_%', '95%_Parametric_CVaR_%']\n",
    "print(f\"\\n95% Confidence VaR/CVaR (%):\")\n",
    "print(risk_metrics_summary[var_95_cols].round(3))\n",
    "\n",
    "# VaR metrics (99% confidence)\n",
    "var_99_cols = ['Strategy', '99%_Historical_VaR_%', '99%_Parametric_VaR_%', '99%_Historical_CVaR_%', '99%_Parametric_CVaR_%']\n",
    "print(f\"\\n99% Confidence VaR/CVaR (%):\")\n",
    "print(risk_metrics_summary[var_99_cols].round(3))\n",
    "\n",
    "# Dollar VaR comparison\n",
    "print(f\"\\nDaily VaR in USD (Historical Method):\")\n",
    "var_comparison = pd.DataFrame()\n",
    "for _, row in risk_metrics_summary.iterrows():\n",
    "    var_comparison = pd.concat([\n",
    "        var_comparison,\n",
    "        pd.DataFrame([{\n",
    "            'Strategy': row['Strategy'],\n",
    "            '95%_VaR_USD': row['95%_Historical_VaR'],\n",
    "            '99%_VaR_USD': row['99%_Historical_VaR'],\n",
    "            '95%_CVaR_USD': row['95%_Historical_CVaR'],\n",
    "            '99%_CVaR_USD': row['99%_Historical_CVaR']\n",
    "        }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "print(var_comparison.round(0))\n",
    "\n",
    "# Risk reduction analysis\n",
    "print(f\"\\nRisk Reduction from Hedging:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "unhedged_var_95 = abs(risk_metrics_summary.loc[0, '95%_Historical_VaR_%'])\n",
    "unhedged_var_99 = abs(risk_metrics_summary.loc[0, '99%_Historical_VaR_%'])\n",
    "\n",
    "for i in range(1, len(hedge_ratios)):\n",
    "    hedge_label = hedge_labels[i]\n",
    "    hedged_var_95 = abs(risk_metrics_summary.loc[i, '95%_Historical_VaR_%'])\n",
    "    hedged_var_99 = abs(risk_metrics_summary.loc[i, '99%_Historical_VaR_%'])\n",
    "    \n",
    "    reduction_95 = (unhedged_var_95 - hedged_var_95) / unhedged_var_95 * 100\n",
    "    reduction_99 = (unhedged_var_99 - hedged_var_99) / unhedged_var_99 * 100\n",
    "    \n",
    "    print(f\"\\n{hedge_label}:\")\n",
    "    print(f\"  95% VaR Reduction: {reduction_95:.1f}%\")\n",
    "    print(f\"  99% VaR Reduction: {reduction_99:.1f}%\")\n",
    "\n",
    "print(\"\\nRisk Metrics Analysis Complete\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Professional Visualizations\n",
    "\n",
    "Comprehensive visual analysis of our currency overlay simulation results including FX rate evolution, portfolio performance, volatility patterns, and risk metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig = plt.figure(figsize=(20, 24))\n",
    "\n",
    "# 1. FX Rates Evolution\n",
    "ax1 = plt.subplot(4, 2, 1)\n",
    "for currency in ['EUR', 'GBP', 'JPY', 'EM_BASKET']:\n",
    "    normalized_rates = fx_rates[currency] / fx_rates[currency].iloc[0]\n",
    "    plt.plot(fx_rates.index, normalized_rates, label=currency, linewidth=2)\n",
    "\n",
    "plt.title('FX Rates Evolution (Normalized to Day 1)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized FX Rate')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Portfolio Value Evolution\n",
    "ax2 = plt.subplot(4, 2, 2)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "for i, (col, color) in enumerate(zip(['unhedged_value', 'partial_hedge_50pct_value', 'full_hedge_100pct_value'], colors)):\n",
    "    if col in portfolio_values_all.columns:\n",
    "        plt.plot(portfolio_values_all.index, portfolio_values_all[col] / 1e6, \n",
    "                label=hedge_labels[i], linewidth=2.5, color=color)\n",
    "\n",
    "plt.title('Portfolio Value Evolution by Hedge Strategy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value ($ Millions)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Daily Returns Distribution\n",
    "ax3 = plt.subplot(4, 2, 3)\n",
    "colors = ['lightblue', 'orange', 'lightgreen']\n",
    "for i, hedge_label in enumerate(hedge_labels):\n",
    "    returns = hedged_results[hedge_label]['total_return'] * 100\n",
    "    plt.hist(returns, bins=30, alpha=0.6, label=hedge_label, color=colors[i], density=True)\n",
    "\n",
    "plt.title('Daily Returns Distribution (%)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Daily Return (%)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Rolling Volatility\n",
    "ax4 = plt.subplot(4, 2, 4)\n",
    "window = 21  # 21-day rolling window\n",
    "for i, hedge_label in enumerate(hedge_labels):\n",
    "    returns = hedged_results[hedge_label]['total_return']\n",
    "    rolling_vol = returns.rolling(window=window).std() * np.sqrt(252) * 100\n",
    "    plt.plot(rolling_vol.index, rolling_vol, label=hedge_label, linewidth=2)\n",
    "\n",
    "plt.title(f'{window}-Day Rolling Volatility (%)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Annualized Volatility (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. VaR Comparison\n",
    "ax5 = plt.subplot(4, 2, 5)\n",
    "strategies = risk_metrics_summary['Strategy'].tolist()\n",
    "var_95 = [abs(x) for x in risk_metrics_summary['95%_Historical_VaR_%'].tolist()]\n",
    "var_99 = [abs(x) for x in risk_metrics_summary['99%_Historical_VaR_%'].tolist()]\n",
    "\n",
    "x = np.arange(len(strategies))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, var_95, width, label='95% VaR', alpha=0.8, color='lightcoral')\n",
    "plt.bar(x + width/2, var_99, width, label='99% VaR', alpha=0.8, color='darkred')\n",
    "\n",
    "plt.title('Value at Risk Comparison (%)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Hedge Strategy')\n",
    "plt.ylabel('VaR (%)')\n",
    "plt.xticks(x, strategies, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Risk-Return Scatter\n",
    "ax6 = plt.subplot(4, 2, 6)\n",
    "annual_returns = risk_metrics_summary['Annual_Return_%'].tolist()\n",
    "annual_vols = risk_metrics_summary['Annual_Volatility_%'].tolist()\n",
    "colors_scatter = ['red', 'orange', 'green']\n",
    "\n",
    "for i, strategy in enumerate(strategies):\n",
    "    plt.scatter(annual_vols[i], annual_returns[i], \n",
    "              s=200, label=strategy, color=colors_scatter[i], alpha=0.7)\n",
    "    plt.annotate(strategy, (annual_vols[i], annual_returns[i]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "plt.title('Risk-Return Profile', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Annual Volatility (%)')\n",
    "plt.ylabel('Annual Return (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Currency Contribution Analysis\n",
    "ax7 = plt.subplot(4, 2, 7)\n",
    "# Use unhedged returns for currency contribution analysis\n",
    "contributions = unhedged_returns[[col for col in unhedged_returns.columns if '_contribution' in col]]\n",
    "contributions.columns = [col.replace('_contribution', '') for col in contributions.columns]\n",
    "\n",
    "# Calculate cumulative contributions\n",
    "cumulative_contributions = (1 + contributions).cumprod()\n",
    "\n",
    "for currency in cumulative_contributions.columns:\n",
    "    plt.plot(cumulative_contributions.index, cumulative_contributions[currency], \n",
    "            label=currency, linewidth=2)\n",
    "\n",
    "plt.title('Cumulative Currency Contributions (Unhedged)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Contribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Drawdown Analysis\n",
    "ax8 = plt.subplot(4, 2, 8)\n",
    "for i, hedge_label in enumerate(hedge_labels):\n",
    "    returns = hedged_results[hedge_label]['total_return']\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    rolling_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - rolling_max) / rolling_max * 100\n",
    "    \n",
    "    plt.plot(drawdown.index, drawdown, label=hedge_label, linewidth=2)\n",
    "\n",
    "plt.title('Portfolio Drawdowns (%)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Drawdown (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.fill_between(drawdown.index, drawdown, 0, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional volatility forecast visualization\n",
    "if volatility_analysis:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Currency Volatility Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    currencies_plot = ['EUR', 'GBP', 'JPY', 'EM_BASKET']\n",
    "    \n",
    "    for i, currency in enumerate(currencies_plot):\n",
    "        if currency in volatility_analysis:\n",
    "            ax = axes[i//2, i%2]\n",
    "            \n",
    "            # Plot rolling volatility\n",
    "            rolling_vol = volatility_analysis[currency]['rolling_vol'] * 100\n",
    "            ax.plot(rolling_vol.index, rolling_vol, label='Historical', linewidth=2, color='blue')\n",
    "            \n",
    "            # Plot forecast if available\n",
    "            if volatility_analysis[currency]['vol_forecast'] is not None:\n",
    "                forecast_vol = volatility_analysis[currency]['vol_forecast'] * np.sqrt(252) * 100\n",
    "                forecast_dates = pd.date_range(start=fx_rates.index[-1], periods=31, freq='D')[1:]\n",
    "                \n",
    "                if len(forecast_dates) == len(forecast_vol):\n",
    "                    ax.plot(forecast_dates, forecast_vol, label='30-day Forecast', \n",
    "                           linewidth=2, color='red', linestyle='--')\n",
    "            \n",
    "            ax.set_title(f'{currency} Volatility (%)', fontweight='bold')\n",
    "            ax.set_ylabel('Annualized Volatility (%)')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"All visualizations generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Strategic Insights and Recommendations\n",
    "\n",
    "Based on our comprehensive analysis, we provide actionable insights for optimal currency overlay strategies across different market conditions and risk scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strategic_insights(risk_metrics_summary, stress_results, hedge_effectiveness):\n",
    "    \"\"\"\n",
    "    Generate actionable insights based on comprehensive analysis\n",
    "    \"\"\"\n",
    "    insights = []\n",
    "    \n",
    "    # Performance Analysis\n",
    "    best_sharpe_idx = risk_metrics_summary['Sharpe_Ratio'].idxmax()\n",
    "    best_sharpe_strategy = risk_metrics_summary.loc[best_sharpe_idx, 'Strategy']\n",
    "    best_sharpe_ratio = risk_metrics_summary.loc[best_sharpe_idx, 'Sharpe_Ratio']\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Performance Optimization',\n",
    "        'insight': f'The {best_sharpe_strategy} demonstrates the highest risk-adjusted returns with a Sharpe ratio of {best_sharpe_ratio:.3f}.',\n",
    "        'recommendation': 'Consider this strategy for long-term portfolio optimization focusing on risk-adjusted returns.'\n",
    "    })\n",
    "    \n",
    "    # Risk Management\n",
    "    lowest_var_idx = risk_metrics_summary['95%_Historical_VaR_%'].abs().idxmin()\n",
    "    lowest_var_strategy = risk_metrics_summary.loc[lowest_var_idx, 'Strategy']\n",
    "    lowest_var = abs(risk_metrics_summary.loc[lowest_var_idx, '95%_Historical_VaR_%'])\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Risk Management',\n",
    "        'insight': f'The {lowest_var_strategy} provides the lowest downside risk with 95% VaR of {lowest_var:.2f}%.',\n",
    "        'recommendation': 'Implement this strategy during periods of high market uncertainty or regulatory capital constraints.'\n",
    "    })\n",
    "    \n",
    "    # Stress Testing Insights\n",
    "    avg_stress_impact = {}\n",
    "    for strategy in ['Unhedged (0%)', 'Partial Hedge (50%)', 'Full Hedge (100%)']:\n",
    "        impacts = [abs(row[f'{strategy}_Impact_%']) for _, row in stress_results.iterrows()]\n",
    "        avg_stress_impact[strategy] = np.mean(impacts)\n",
    "    \n",
    "    most_resilient = min(avg_stress_impact, key=avg_stress_impact.get)\n",
    "    resilience_score = avg_stress_impact[most_resilient]\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Stress Resilience',\n",
    "        'insight': f'Under extreme stress scenarios, {most_resilient} shows the highest resilience with average impact of {resilience_score:.2f}%.',\n",
    "        'recommendation': 'Deploy this strategy during anticipated periods of FX volatility or geopolitical uncertainty.'\n",
    "    })\n",
    "    \n",
    "    # Cost-Benefit Analysis\n",
    "    hedging_benefits = hedge_effectiveness['50%_Hedge_Reduction'].mean()\n",
    "    full_hedging_benefits = hedge_effectiveness['100%_Hedge_Reduction'].mean()\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Cost-Benefit Optimization',\n",
    "        'insight': f'Partial hedging (50%) provides {hedging_benefits:.1f}% risk reduction while full hedging provides {full_hedging_benefits:.1f}%.',\n",
    "        'recommendation': 'Consider partial hedging as it offers substantial risk reduction with lower hedging costs.'\n",
    "    })\n",
    "    \n",
    "    # Market Regime Analysis\n",
    "    high_vol_periods = fx_returns.std().nlargest(2).index.tolist()\n",
    "    low_vol_periods = fx_returns.std().nsmallest(2).index.tolist()\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Market Regime Adaptation',\n",
    "        'insight': f'Currency volatility varies significantly across currencies: {high_vol_periods} show highest volatility.',\n",
    "        'recommendation': 'Implement dynamic hedge ratios that increase exposure to high-volatility currencies during favorable conditions.'\n",
    "    })\n",
    "    \n",
    "    return insights\n",
    "\n",
    "def calculate_optimal_hedge_ratio(risk_metrics_summary, target_vol=None, target_return=None):\n",
    "    \"\"\"\n",
    "    Calculate optimal hedge ratio based on specific objectives\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Risk minimization\n",
    "    min_vol_idx = risk_metrics_summary['Annual_Volatility_%'].idxmin()\n",
    "    results['risk_minimization'] = {\n",
    "        'strategy': risk_metrics_summary.loc[min_vol_idx, 'Strategy'],\n",
    "        'volatility': risk_metrics_summary.loc[min_vol_idx, 'Annual_Volatility_%'],\n",
    "        'return': risk_metrics_summary.loc[min_vol_idx, 'Annual_Return_%']\n",
    "    }\n",
    "    \n",
    "    # Return maximization\n",
    "    max_return_idx = risk_metrics_summary['Annual_Return_%'].idxmax()\n",
    "    results['return_maximization'] = {\n",
    "        'strategy': risk_metrics_summary.loc[max_return_idx, 'Strategy'],\n",
    "        'volatility': risk_metrics_summary.loc[max_return_idx, 'Annual_Volatility_%'],\n",
    "        'return': risk_metrics_summary.loc[max_return_idx, 'Annual_Return_%']\n",
    "    }\n",
    "    \n",
    "    # Sharpe maximization\n",
    "    max_sharpe_idx = risk_metrics_summary['Sharpe_Ratio'].idxmax()\n",
    "    results['sharpe_maximization'] = {\n",
    "        'strategy': risk_metrics_summary.loc[max_sharpe_idx, 'Strategy'],\n",
    "        'volatility': risk_metrics_summary.loc[max_sharpe_idx, 'Annual_Volatility_%'],\n",
    "        'return': risk_metrics_summary.loc[max_sharpe_idx, 'Annual_Return_%'],\n",
    "        'sharpe': risk_metrics_summary.loc[max_sharpe_idx, 'Sharpe_Ratio']\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate insights\n",
    "print(\"Generating Strategic Insights...\")\n",
    "strategic_insights = generate_strategic_insights(risk_metrics_summary, stress_results, hedge_effectiveness)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGIC INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, insight in enumerate(strategic_insights, 1):\n",
    "    print(f\"\\n{i}. {insight['category'].upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Analysis: {insight['insight']}\")\n",
    "    print(f\"Recommendation: {insight['recommendation']}\")\n",
    "\n",
    "# Calculate optimal strategies\n",
    "optimal_strategies = calculate_optimal_hedge_ratio(risk_metrics_summary)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMAL HEDGE RATIO RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for objective, details in optimal_strategies.items():\n",
    "    print(f\"\\n{objective.replace('_', ' ').title()}:\")\n",
    "    print(f\"   Recommended Strategy: {details['strategy']}\")\n",
    "    print(f\"   Expected Return: {details['return']:.2f}%\")\n",
    "    print(f\"   Expected Volatility: {details['volatility']:.2f}%\")\n",
    "    if 'sharpe' in details:\n",
    "        print(f\"   Sharpe Ratio: {details['sharpe']:.3f}\")\n",
    "\n",
    "# Implementation roadmap\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"IMPLEMENTATION ROADMAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "implementation_steps = [\n",
    "    {\n",
    "        'phase': 'Phase 1: Foundation (Weeks 1-2)',\n",
    "        'actions': [\n",
    "            'Establish FX data feeds and risk measurement infrastructure',\n",
    "            'Implement basic VaR/CVaR calculation capabilities',\n",
    "            'Set up portfolio exposure tracking by currency'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'phase': 'Phase 2: Strategy Development (Weeks 3-4)',\n",
    "        'actions': [\n",
    "            'Develop dynamic hedge ratio adjustment mechanisms',\n",
    "            'Implement stress testing framework',\n",
    "            'Create real-time volatility monitoring'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'phase': 'Phase 3: Optimization (Weeks 5-6)',\n",
    "        'actions': [\n",
    "            'Deploy GARCH-based volatility forecasting',\n",
    "            'Integrate market regime detection',\n",
    "            'Establish automated hedge ratio recommendations'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'phase': 'Phase 4: Monitoring (Ongoing)',\n",
    "        'actions': [\n",
    "            'Daily risk metric calculation and reporting',\n",
    "            'Monthly strategy performance review',\n",
    "            'Quarterly model validation and recalibration'\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for step in implementation_steps:\n",
    "    print(f\"\\n{step['phase']}\")\n",
    "    for action in step['actions']:\n",
    "        print(f\"   • {action}\")\n",
    "\n",
    "# Key Performance Indicators\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERFORMANCE INDICATORS (KPIs)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "kpis = [\n",
    "    {'metric': 'Portfolio Volatility', 'target': '< 15% annually', 'frequency': 'Daily'},\n",
    "    {'metric': '95% VaR', 'target': '< 2.5% daily', 'frequency': 'Daily'},\n",
    "    {'metric': 'Sharpe Ratio', 'target': '> 0.8', 'frequency': 'Monthly'},\n",
    "    {'metric': 'Maximum Drawdown', 'target': '< 8%', 'frequency': 'Monthly'},\n",
    "    {'metric': 'Hedge Effectiveness', 'target': '> 70% in stress scenarios', 'frequency': 'Quarterly'},\n",
    "    {'metric': 'Model Accuracy', 'target': '> 85% forecast accuracy', 'frequency': 'Quarterly'}\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Target':<25} {'Frequency':<15}\")\n",
    "print(\"-\" * 60)\n",
    "for kpi in kpis:\n",
    "    print(f\"{kpi['metric']:<20} {kpi['target']:<25} {kpi['frequency']:<15}\")\n",
    "\n",
    "# Risk warnings and considerations\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"RISK WARNINGS AND CONSIDERATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "warnings = [\n",
    "    \"Model Risk: GARCH and ARIMA models may not capture extreme market events\",\n",
    "    \"Hedging Costs: Transaction costs and bid-ask spreads can erode hedging benefits\",\n",
    "    \"Basis Risk: Imperfect correlation between hedge instruments and portfolio exposures\",\n",
    "    \"Liquidity Risk: FX hedging instruments may become illiquid during stress periods\",\n",
    "    \"Regulatory Risk: Changes in derivatives regulations may impact hedging strategies\"\n",
    "]\n",
    "\n",
    "for i, warning in enumerate(warnings, 1):\n",
    "    print(f\"\\n{i}. {warning}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE - READY FOR IMPLEMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Summary statistics for final review\n",
    "final_summary = {\n",
    "    'simulation_days': SIMULATION_DAYS,\n",
    "    'portfolio_value': f\"${INITIAL_PORTFOLIO_VALUE:,.0f}\",\n",
    "    'currencies_analyzed': len(currencies),\n",
    "    'hedge_strategies': len(hedge_ratios),\n",
    "    'stress_scenarios': len(stress_scenarios),\n",
    "    'best_strategy': optimal_strategies['sharpe_maximization']['strategy'],\n",
    "    'risk_reduction': f\"{hedge_effectiveness['50%_Hedge_Reduction'].mean():.1f}%\"\n",
    "}\n",
    "\n",
    "print(f\"\\nFinal Summary:\")\n",
    "for key, value in final_summary.items():\n",
    "    print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(f\"\\nCurrency Overlay Simulation Engine Complete!\")\n",
    "print(f\"Ready for production deployment and real-time risk management.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This Currency Overlay Simulation Engine provides a comprehensive framework for analyzing and optimizing FX hedging strategies in multi-currency portfolios. The simulation demonstrates:\n",
    "\n",
    "### **Key Deliverables Achieved:**\n",
    "- **Synthetic FX Data Generation**: 180-day simulation with realistic market dynamics\n",
    "- **Multi-Currency Portfolio Modeling**: Realistic exposure weightings and performance tracking  \n",
    "- **Dynamic Hedging Analysis**: Comprehensive comparison of 0%, 50%, and 100% hedge ratios\n",
    "- **Advanced Risk Modeling**: ARIMA-GARCH volatility forecasting and clustering analysis\n",
    "- **Stress Testing Framework**: Extreme scenario analysis with hedge effectiveness measurement\n",
    "- **Risk Metrics Calculation**: VaR/CVaR using multiple methodologies (Historical, Parametric, Monte Carlo)\n",
    "- **Professional Visualizations**: 8 comprehensive charts covering all aspects of the analysis\n",
    "- **Actionable Insights**: Strategic recommendations with implementation roadmap\n",
    "\n",
    "### **Strategic Value:**\n",
    "This simulation engine enables portfolio managers to:\n",
    "- **Optimize hedge ratios** based on risk tolerance and return objectives\n",
    "- **Quantify hedging benefits** through comprehensive stress testing\n",
    "- **Forecast risk profiles** using advanced time series models\n",
    "- **Make data-driven decisions** supported by robust risk metrics\n",
    "- **Implement dynamic strategies** that adapt to changing market conditions\n",
    "\n",
    "### **Next Steps:**\n",
    "- Deploy the framework with real-time FX data feeds\n",
    "- Integrate with existing portfolio management systems\n",
    "- Implement automated hedge ratio optimization\n",
    "- Establish monitoring and alerting systems\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** This simulation uses synthetic data for demonstration purposes. For production use, integrate with real market data and validate model parameters with historical performance.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
